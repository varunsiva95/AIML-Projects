{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Questions - Project 1 - Sequential Models in NLP - Sentiment Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXaFSkUu0fzm"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=1UXScsVx_Wni_JuDdB8LeTnM6jsPfIwkW)\n",
        "\n",
        "Proprietary content. Â© Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OudB5by50jlI"
      },
      "source": [
        "# Sentiment Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT7MKZuMRaCg"
      },
      "source": [
        "### Dataset\n",
        "- Dataset of 50,000 movie reviews from IMDB, labeled by sentiment positive (1) or negative (0)\n",
        "- Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers).\n",
        "- For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n",
        "- As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
        "\n",
        "Command to import data\n",
        "- `from tensorflow.keras.datasets import imdb`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q34-Y3nRKXdO"
      },
      "source": [
        "### Import the data (2 Marks)\n",
        "- Use `imdb.load_data()` method\n",
        "- Get train and test set\n",
        "- Take 10000 most frequent words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8S09mZtm4Q-"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxfwbrbuKbk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43b0326-660e-440c-b419-e70c2e175715"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DldivBO4LTbP"
      },
      "source": [
        "### Pad each sentence to be of same length (2 Marks)\n",
        "- Take maximum sequence length as 300"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E808XB4tLtic"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "#Define maximum number of words to consider in each review\r\n",
        "max_review_length = 300\r\n",
        "#Pad training and test reviews\r\n",
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\r\n",
        "                                                        maxlen=max_review_length,\r\n",
        "                                                        padding='pre', truncating='post')\r\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, \r\n",
        "                                                       maxlen=max_review_length, \r\n",
        "                                                       padding='pre', truncating='post')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBFFCrybMSXz"
      },
      "source": [
        "### Print shape of features & labels (2 Marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOcyRtZfMYZd"
      },
      "source": [
        "Number of review, number of words in each review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdMCUPr7RaCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488a0521-2f58-4963-8093-44b52e383471"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "print('Number of reviews in training set: ', len(X_train))\r\n",
        "print('Number of words in each review in training set: ', len(X_train[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews in training set:  25000\n",
            "Number of words in each review in training set:  300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGVHeKOWyJiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb839cbd-6c15-40d2-c82d-2f3260ed1eec"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "print('Number of reviews in test set: ', len(X_test))\r\n",
        "print('Number of words in each review in test set: ', len(X_test[0]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews in test set:  25000\n",
            "Number of words in each review in test set:  300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cNk5sDvMr3j"
      },
      "source": [
        "Number of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z00-mYgMoKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a406bb-cdb3-4e5a-e111-0645edba7861"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "print('Number of labels in training set: ', len(y_train))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labels in training set:  25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7f5tPeaMxti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec5df40-8ac4-4cfa-deeb-c604853b51dc"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "print('Number of labels in test set: ', len(y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labels in test set:  25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdXPWuOmNEbh"
      },
      "source": [
        "### Print value of any one feature and it's label (2 Marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGLEdeFmNZfR"
      },
      "source": [
        "Feature value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKFyMa28zztL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ed5e7b-de3e-434d-eee9-3279c59b6bbe"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "print('Feature for 1st review in training set= ', X_train[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature for 1st review in training set=  [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    1   14\n",
            "   22   16   43  530  973 1622 1385   65  458 4468   66 3941    4  173\n",
            "   36  256    5   25  100   43  838  112   50  670    2    9   35  480\n",
            "  284    5  150    4  172  112  167    2  336  385   39    4  172 4536\n",
            " 1111   17  546   38   13  447    4  192   50   16    6  147 2025   19\n",
            "   14   22    4 1920 4613  469    4   22   71   87   12   16   43  530\n",
            "   38   76   15   13 1247    4   22   17  515   17   12   16  626   18\n",
            "    2    5   62  386   12    8  316    8  106    5    4 2223 5244   16\n",
            "  480   66 3785   33    4  130   12   16   38  619    5   25  124   51\n",
            "   36  135   48   25 1415   33    6   22   12  215   28   77   52    5\n",
            "   14  407   16   82    2    8    4  107  117 5952   15  256    4    2\n",
            "    7 3766    5  723   36   71   43  530  476   26  400  317   46    7\n",
            "    4    2 1029   13  104   88    4  381   15  297   98   32 2071   56\n",
            "   26  141    6  194 7486   18    4  226   22   21  134  476   26  480\n",
            "    5  144   30 5535   18   51   36   28  224   92   25  104    4  226\n",
            "   65   16   38 1334   88   12   16  283    5   16 4472  113  103   32\n",
            "   15   16 5345   19  178   32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_85Hqm0Nb1I"
      },
      "source": [
        "Label value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FoehB5jNd1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83088197-a93e-40ae-cad5-c400f738a69d"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "print('Label for 1st review in training set = ', y_train[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label for 1st review in training set =  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cof4LSxNxuv"
      },
      "source": [
        "### Decode the feature value to get original sentence (2 Marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_oiAyPZOkJD"
      },
      "source": [
        "First, retrieve a dictionary that contains mapping of words to their index in the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clsk-yK8OtzD"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "word_to_id = imdb.get_word_index()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRgOD5S2Uuvd"
      },
      "source": [
        "Now use the dictionary to get the original words from the encodings, for a particular sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjMWU-wxrGWl",
        "outputId": "70add15c-b58b-43b9-9a96-3beebb002366"
      },
      "source": [
        "INDEX_FROM=3\r\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\r\n",
        "word_to_id[\"<PAD>\"] = 0\r\n",
        "word_to_id[\"<START>\"] = 1\r\n",
        "word_to_id[\"<UNK>\"] = 2\r\n",
        "word_to_id[\"<UNUSED>\"] = 3\r\n",
        "\r\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}\r\n",
        "#Getting decoded value for feature in index 7\r\n",
        "print(' '.join(id_to_word[id] for id in X_train[7] ))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> the <UNK> tells the story of the four hamilton siblings teenager francis <UNK> <UNK> twins <UNK> joseph <UNK> <UNK> <UNK> <UNK> the <UNK> david samuel who is now the surrogate parent in charge the <UNK> move house a lot <UNK> is unsure why is unhappy with the way things are the fact that his brother's sister kidnap <UNK> murder people in the basement doesn't help relax or calm <UNK> nerves either francis <UNK> something just isn't right when he eventually finds out the truth things will never be the same again br br co written co produced directed by mitchell <UNK> phil <UNK> as the butcher brothers who's only other film director's credit so far is the april <UNK> day 2008 remake enough said this was one of the <UNK> to die <UNK> at the 2006 after dark <UNK> or whatever it's called in keeping with pretty much all the other's i've seen i thought the <UNK> was complete total utter crap i found the character's really poor very unlikable the slow moving story failed to capture my imagination or sustain my interest over it's 85 a half minute too long <UNK> minute duration the there's the awful twist at the end which had me laughing out loud there's this really big <UNK> build up to what's inside a <UNK> thing in the <UNK> basement it's eventually revealed to be a little boy with a teddy is that really supposed to scare us is that really supposed to shock us is that really something that is supposed to have us talking about it as the end credits roll is a harmless looking young boy the best <UNK> ending that the makers could come up with the boring plot <UNK> along it's never made clear where the <UNK> get all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLGABrJoVZe6"
      },
      "source": [
        "Get the sentiment for the above sentence\n",
        "- positive (1)\n",
        "- negative (0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDyQGJT0Ve-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e51cc4d-03a2-430d-b134-ca7c6a0ab5ba"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "if y_train[7] == 1:\r\n",
        "  print('Positive')\r\n",
        "else:\r\n",
        "  print('Negative')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmCjr8miXIWB"
      },
      "source": [
        "### Define model (10 Marks)\n",
        "- Define a Sequential Model\n",
        "- Add Embedding layer\n",
        "  - Embedding layer turns positive integers into dense vectors of fixed size\n",
        "  - `tensorflow.keras` embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unique integer number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn LabelEncoder.\n",
        "  - Size of the vocabulary will be 10000\n",
        "  - Give dimension of the dense embedding as 100\n",
        "  - Length of input sequences should be 300\n",
        "- Add LSTM layer\n",
        "  - Pass value in `return_sequences` as True\n",
        "- Add a `TimeDistributed` layer with 100 Dense neurons\n",
        "- Add Flatten layer\n",
        "- Add Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np5GxT1caFEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8839ce-a267-4203-d6af-c33ac8515d7f"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "#Initialize model\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "model = tf.keras.Sequential()\r\n",
        "#Adding Embdedding Layer\r\n",
        "model.add(tf.keras.layers.Embedding(input_dim= 10000 + 1, #Vocablury size\r\n",
        "                                    output_dim = 100, \r\n",
        "                                    trainable=True,\r\n",
        "                                    input_length=300) #Number of words in each review\r\n",
        "          )\r\n",
        "#Adding LSTM Layer\r\n",
        "model.add(tf.keras.layers.Dropout(0.8))\r\n",
        "model.add(tf.keras.layers.LSTM(256, return_sequences=True, recurrent_dropout= 0.8, dropout = 0.8)) #RNN State - size of cell state and hidden state\r\n",
        "\r\n",
        "\r\n",
        "#Adding time distributed layer\r\n",
        "model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(100,activation='relu')))\r\n",
        "model.add(tf.keras.layers.Dropout(0.8))\r\n",
        "\r\n",
        "#Adding Flatten Layer\r\n",
        "model.add(tf.keras.layers.Flatten())\r\n",
        "\r\n",
        "#Adding Dense Layer\r\n",
        "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc4bknOobDby"
      },
      "source": [
        "### Compile the model (2 Marks)\n",
        "- Use Optimizer as Adam\n",
        "- Use Binary Crossentropy as loss\n",
        "- Use Accuracy as metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw4RJ0CQbwFY"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = 'accuracy')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sEzwazqbz3T"
      },
      "source": [
        "### Print model summary (2 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hx1yxwlb2Ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749d6097-5c72-41dc-83b3-f7fd52393228"
      },
      "source": [
        "### Add your code here ####\r\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 300, 100)          1000100   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 300, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 300, 256)          365568    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 300, 100)          25700     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 300, 100)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 30001     \n",
            "=================================================================\n",
            "Total params: 1,421,369\n",
            "Trainable params: 1,421,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmkolKP4b-U6"
      },
      "source": [
        "### Fit the model (2 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRg3KFXLcAkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a738f10b-b971-4bb8-ae29-97a75829d7e7"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "model.fit(X_train, y_train,batch_size=256, epochs=20 , validation_data=(X_test,y_test), verbose = True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "98/98 [==============================] - 114s 1s/step - loss: 0.6942 - accuracy: 0.5082 - val_loss: 0.6434 - val_accuracy: 0.6279\n",
            "Epoch 2/20\n",
            "98/98 [==============================] - 110s 1s/step - loss: 0.6075 - accuracy: 0.6667 - val_loss: 0.3846 - val_accuracy: 0.8446\n",
            "Epoch 3/20\n",
            "98/98 [==============================] - 110s 1s/step - loss: 0.4136 - accuracy: 0.8161 - val_loss: 0.3521 - val_accuracy: 0.8507\n",
            "Epoch 4/20\n",
            "98/98 [==============================] - 111s 1s/step - loss: 0.3584 - accuracy: 0.8434 - val_loss: 0.3058 - val_accuracy: 0.8798\n",
            "Epoch 5/20\n",
            "98/98 [==============================] - 111s 1s/step - loss: 0.3299 - accuracy: 0.8605 - val_loss: 0.3004 - val_accuracy: 0.8836\n",
            "Epoch 6/20\n",
            "98/98 [==============================] - 110s 1s/step - loss: 0.3005 - accuracy: 0.8715 - val_loss: 0.2857 - val_accuracy: 0.8849\n",
            "Epoch 7/20\n",
            "98/98 [==============================] - 111s 1s/step - loss: 0.3002 - accuracy: 0.8736 - val_loss: 0.2923 - val_accuracy: 0.8804\n",
            "Epoch 8/20\n",
            "98/98 [==============================] - 110s 1s/step - loss: 0.2801 - accuracy: 0.8842 - val_loss: 0.2768 - val_accuracy: 0.8871\n",
            "Epoch 9/20\n",
            "98/98 [==============================] - 112s 1s/step - loss: 0.2729 - accuracy: 0.8856 - val_loss: 0.2794 - val_accuracy: 0.8856\n",
            "Epoch 10/20\n",
            "98/98 [==============================] - 113s 1s/step - loss: 0.2644 - accuracy: 0.8927 - val_loss: 0.2914 - val_accuracy: 0.8801\n",
            "Epoch 11/20\n",
            "98/98 [==============================] - 111s 1s/step - loss: 0.2455 - accuracy: 0.8986 - val_loss: 0.3049 - val_accuracy: 0.8711\n",
            "Epoch 12/20\n",
            "98/98 [==============================] - 110s 1s/step - loss: 0.2381 - accuracy: 0.9040 - val_loss: 0.2783 - val_accuracy: 0.8870\n",
            "Epoch 13/20\n",
            "98/98 [==============================] - 111s 1s/step - loss: 0.2289 - accuracy: 0.9091 - val_loss: 0.2948 - val_accuracy: 0.8868\n",
            "Epoch 14/20\n",
            "98/98 [==============================] - 111s 1s/step - loss: 0.2185 - accuracy: 0.9104 - val_loss: 0.3211 - val_accuracy: 0.8723\n",
            "Epoch 15/20\n",
            "98/98 [==============================] - 111s 1s/step - loss: 0.2182 - accuracy: 0.9123 - val_loss: 0.3292 - val_accuracy: 0.8721\n",
            "Epoch 16/20\n",
            "98/98 [==============================] - 110s 1s/step - loss: 0.2079 - accuracy: 0.9193 - val_loss: 0.3003 - val_accuracy: 0.8839\n",
            "Epoch 17/20\n",
            "98/98 [==============================] - 110s 1s/step - loss: 0.1960 - accuracy: 0.9219 - val_loss: 0.3340 - val_accuracy: 0.8755\n",
            "Epoch 18/20\n",
            "98/98 [==============================] - 109s 1s/step - loss: 0.1889 - accuracy: 0.9239 - val_loss: 0.3007 - val_accuracy: 0.8818\n",
            "Epoch 19/20\n",
            "98/98 [==============================] - 109s 1s/step - loss: 0.1848 - accuracy: 0.9281 - val_loss: 0.3138 - val_accuracy: 0.8804\n",
            "Epoch 20/20\n",
            "98/98 [==============================] - 111s 1s/step - loss: 0.1676 - accuracy: 0.9341 - val_loss: 0.3303 - val_accuracy: 0.8795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2591ba6790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwLl54MXnkEA"
      },
      "source": [
        "### Evaluate model (2 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUqY-bD8RaDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ebb41b-3c35-4fed-f2c8-ab1adb397e25"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 55s 71ms/step - loss: 0.3303 - accuracy: 0.8795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33032694458961487, 0.8795199990272522]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2amr1tJn9Jz"
      },
      "source": [
        "### Predict on one sample (2 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl4idfWR_A8E"
      },
      "source": [
        "#### Add your code here ####\r\n",
        "predictions = model.predict(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf76jD5guCz7"
      },
      "source": [
        "#Using a threshold of 0.5 to convert the predictions to binary format\r\n",
        "binary_pred = []\r\n",
        "for pred in predictions:\r\n",
        "  if pred <= 0.5:\r\n",
        "    binary_pred.append(0)\r\n",
        "  else:\r\n",
        "    binary_pred.append(1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tUNzCGxvYYf",
        "outputId": "923d66a1-6d98-4105-8abc-238e80262272"
      },
      "source": [
        "#Raw model prediction for the review in index 1 in the test set\r\n",
        "predictions[1]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9999989], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALQpZlYFmkfl",
        "outputId": "87be0f24-dff7-4273-8d85-12b5d6a4094a"
      },
      "source": [
        "#Looking at the prediction for the review in index 1 in the test set\r\n",
        "binary_pred[1]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_KS7iMy6Ie1",
        "outputId": "2880ab1c-3b2c-4c3b-e76e-466e5617a72e"
      },
      "source": [
        "#Looking at the label for the review in index 1 in the test set\r\n",
        "y_test[1]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e8BeexGm0NQ",
        "outputId": "fdeaa2f4-0de3-4958-d538-32a8e5ce6c36"
      },
      "source": [
        "#Looking at the actual review in index 1 in the test set\r\n",
        "print(' '.join(id_to_word[id] for id in X_test[1] ))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> this film requires a lot of patience because it focuses on mood and character development the plot is very simple and many of the scenes take place on the same set in frances <UNK> the sandy dennis character apartment but the film builds to a disturbing climax br br the characters create an atmosphere <UNK> with sexual tension and psychological <UNK> it's very interesting that robert altman directed this considering the style and structure of his other films still the trademark altman audio style is evident here and there i think what really makes this film work is the brilliant performance by sandy dennis it's definitely one of her darker characters but she plays it so perfectly and convincingly that it's scary michael burns does a good job as the mute young man regular altman player michael murphy has a small part the <UNK> moody set fits the content of the story very well in short this movie is a powerful study of loneliness sexual <UNK> and desperation be patient <UNK> up the atmosphere and pay attention to the wonderfully written script br br i praise robert altman this is one of his many films that deals with unconventional fascinating subject matter this film is disturbing but it's sincere and it's sure to <UNK> a strong emotional response from the viewer if you want to see an unusual film some might even say bizarre this is worth the time br br unfortunately it's very difficult to find in video stores you may have to buy it off the internet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHUJsoCIGajM"
      },
      "source": [
        "Thus we can see that the model has correctly identified the review as a positive one !"
      ]
    }
  ]
}